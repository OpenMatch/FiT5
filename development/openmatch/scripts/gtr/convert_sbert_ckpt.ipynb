{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv_openmatch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "gtr_dir = \"/pretrained_models/gtr-t5-base\"\n",
    "linear_dir = os.path.join(gtr_dir, \"2_Dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = sentence_transformers.models.Dense.load(linear_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.0422, -0.0312,  0.0625,  ...,  0.0703, -0.0718,  0.0017],\n",
      "        [-0.0518, -0.0613, -0.0449,  ...,  0.0253, -0.0045,  0.0698],\n",
      "        [ 0.0009,  0.0007, -0.0325,  ..., -0.0182, -0.0205,  0.0012],\n",
      "        ...,\n",
      "        [-0.0742, -0.0466,  0.0645,  ..., -0.0114, -0.0244,  0.0630],\n",
      "        [ 0.0261, -0.0306,  0.0410,  ...,  0.0049, -0.0132, -0.0124],\n",
      "        [-0.0737,  0.0815,  0.0023,  ..., -0.0615,  0.0520,  0.0223]]))])\n"
     ]
    }
   ],
   "source": [
    "print(dense_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear_q.weight', tensor([[-0.0130,  0.0267, -0.0248,  ...,  0.0253, -0.0267, -0.0267],\n",
      "        [ 0.0110,  0.0041,  0.0282,  ...,  0.0211, -0.0159,  0.0135],\n",
      "        [-0.0280,  0.0325, -0.0296,  ...,  0.0038,  0.0218,  0.0221],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0043, -0.0109,  ...,  0.0237,  0.0022, -0.0326],\n",
      "        [ 0.0302,  0.0346,  0.0184,  ...,  0.0204, -0.0359, -0.0103],\n",
      "        [-0.0108, -0.0178, -0.0069,  ...,  0.0132,  0.0077, -0.0336]])), ('linear_p.weight', tensor([[-0.0130,  0.0267, -0.0248,  ...,  0.0253, -0.0267, -0.0267],\n",
      "        [ 0.0110,  0.0041,  0.0282,  ...,  0.0211, -0.0159,  0.0135],\n",
      "        [-0.0280,  0.0325, -0.0296,  ...,  0.0038,  0.0218,  0.0221],\n",
      "        ...,\n",
      "        [ 0.0304,  0.0043, -0.0109,  ...,  0.0237,  0.0022, -0.0326],\n",
      "        [ 0.0302,  0.0346,  0.0184,  ...,  0.0204, -0.0359, -0.0103],\n",
      "        [-0.0108, -0.0178, -0.0069,  ...,  0.0132,  0.0077, -0.0336]]))])\n"
     ]
    }
   ],
   "source": [
    "from openmatch.modeling import LinearHead\n",
    "\n",
    "new_linear = LinearHead(768, 768, True)\n",
    "print(new_linear.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear_q.weight', tensor([[ 0.0422, -0.0312,  0.0625,  ...,  0.0703, -0.0718,  0.0017],\n",
      "        [-0.0518, -0.0613, -0.0449,  ...,  0.0253, -0.0045,  0.0698],\n",
      "        [ 0.0009,  0.0007, -0.0325,  ..., -0.0182, -0.0205,  0.0012],\n",
      "        ...,\n",
      "        [-0.0742, -0.0466,  0.0645,  ..., -0.0114, -0.0244,  0.0630],\n",
      "        [ 0.0261, -0.0306,  0.0410,  ...,  0.0049, -0.0132, -0.0124],\n",
      "        [-0.0737,  0.0815,  0.0023,  ..., -0.0615,  0.0520,  0.0223]])), ('linear_p.weight', tensor([[ 0.0422, -0.0312,  0.0625,  ...,  0.0703, -0.0718,  0.0017],\n",
      "        [-0.0518, -0.0613, -0.0449,  ...,  0.0253, -0.0045,  0.0698],\n",
      "        [ 0.0009,  0.0007, -0.0325,  ..., -0.0182, -0.0205,  0.0012],\n",
      "        ...,\n",
      "        [-0.0742, -0.0466,  0.0645,  ..., -0.0114, -0.0244,  0.0630],\n",
      "        [ 0.0261, -0.0306,  0.0410,  ...,  0.0049, -0.0132, -0.0124],\n",
      "        [-0.0737,  0.0815,  0.0023,  ..., -0.0615,  0.0520,  0.0223]]))])\n"
     ]
    }
   ],
   "source": [
    "new_linear.linear_q.weight.data = dense_model.linear.weight.data\n",
    "print(new_linear.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_linear.save_pooler(\"/pretrained_models/gtr-t5-base-openmatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5EncoderModel\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5EncoderModel, AutoTokenizer, AutoModel\n",
    "\n",
    "gtr_model = T5EncoderModel.from_pretrained(gtr_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(gtr_dir)\n",
    "print(type(gtr_model).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/pretrained_models/gtr-t5-base-openmatch/tokenizer_config.json',\n",
       " '/pretrained_models/gtr-t5-base-openmatch/special_tokens_map.json',\n",
       " '/pretrained_models/gtr-t5-base-openmatch/spiece.model',\n",
       " '/pretrained_models/gtr-t5-base-openmatch/added_tokens.json',\n",
       " '/pretrained_models/gtr-t5-base-openmatch/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtr_model.save_pretrained(\"/pretrained_models/gtr-t5-base-openmatch\")\n",
    "tokenizer.save_pretrained(\"/pretrained_models/gtr-t5-base-openmatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"plm_backbone\": {\n",
    "        \"type\": type(gtr_model).__name__,\n",
    "        \"feature\": \"last_hidden_state\",\n",
    "    },\n",
    "    \"pooling\": \"mean\",\n",
    "    \"linear_head\": {\n",
    "        \"input_dim\": 768,\n",
    "        \"output_dim\": 768,\n",
    "        \"tied\": True\n",
    "    },\n",
    "    \"normalize\": True,\n",
    "}\n",
    "import json\n",
    "with open(\"/pretrained_models/gtr-t5-base-openmatch/openmatch_config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv_openmatch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello???\n"
     ]
    }
   ],
   "source": [
    "from openmatch.arguments import ModelArguments\n",
    "\n",
    "model_args = ModelArguments(model_name_or_path=\"/pretrained_models/gtr-t5-base-openmatch\", encoder_only=True)\n",
    "\n",
    "from openmatch.modeling import DenseModelForInference\n",
    "\n",
    "model = DenseModelForInference.build(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 4308,    19,     8,  1784,    13,  3434,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 4308,    19,     3,     9,   508,   690,    16,  3434,     1,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 4738,     7,   127,  7631,    54,    36,   261,    21,  1659,  1036,\n",
      "             1,     0,     0,     0,     0,     0,     0],\n",
      "        [12901,    17,   127,   524,     6,  1597,    57,  1376,  7833,     6,\n",
      "            19,     3,     9,  1659,  1036,  4732,     1],\n",
      "        [   27,     7,   180,  3389,    63,    42,   206,  1167,    63,   394,\n",
      "            58,     1,     0,     0,     0,     0,     0],\n",
      "        [ 4073,    19,  3627,    10,     3,     7,  3389,    63,    42,  2131,\n",
      "          7664,    58,     1,     0,     0,     0,     0],\n",
      "        [ 3431,     7,    54,   619,    21,   882,     3,     9,   307,    97,\n",
      "             1,     0,     0,     0,     0,     0,     0],\n",
      "        [ 3431,     7,    33,  6917,   200,  1565,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "english_sentences = [\"Berlin is the capital of Germany\", \"Berlin is a large city in Germany\",\n",
    "                     \"Tensorflow can be used for deep learning\", \"Pytorch, developed by Facebook AI, is a deep learning framework\",\n",
    "                    \"Is Scipy or numpy better?\", \"Which is faster: scipy or pandas?\",\n",
    "                    \"Cats can live for quite a long time\", \"Cats are humans best friend\"]\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/pretrained_models/gtr-t5-base-openmatch\")\n",
    "encoded_input = tokenizer(english_sentences, return_tensors=\"pt\", padding=True)\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 17, 768])\n",
      "torch.Size([8, 17, 768])\n",
      "final\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.8741, 0.3953, 0.4471, 0.3823, 0.3676, 0.3727, 0.4211],\n",
       "        [0.8741, 1.0000, 0.4013, 0.4346, 0.3300, 0.3374, 0.4055, 0.3853],\n",
       "        [0.3953, 0.4013, 1.0000, 0.6366, 0.5313, 0.5230, 0.3930, 0.4091],\n",
       "        [0.4471, 0.4346, 0.6366, 1.0000, 0.5341, 0.5523, 0.4042, 0.4882],\n",
       "        [0.3823, 0.3300, 0.5313, 0.5341, 1.0000, 0.7789, 0.4009, 0.4493],\n",
       "        [0.3676, 0.3374, 0.5230, 0.5523, 0.7789, 1.0000, 0.4256, 0.4364],\n",
       "        [0.3727, 0.4055, 0.3930, 0.4042, 0.4009, 0.4256, 1.0000, 0.6377],\n",
       "        [0.4211, 0.3853, 0.4091, 0.4882, 0.4493, 0.4364, 0.6377, 1.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "hidden, reps = model.encode_passage(encoded_input)\n",
    "util.dot_score(reps, reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear_q.weight', tensor([[ 0.0422, -0.0312,  0.0625,  ...,  0.0703, -0.0718,  0.0017],\n",
      "        [-0.0518, -0.0613, -0.0449,  ...,  0.0253, -0.0045,  0.0698],\n",
      "        [ 0.0009,  0.0007, -0.0325,  ..., -0.0182, -0.0205,  0.0012],\n",
      "        ...,\n",
      "        [-0.0742, -0.0466,  0.0645,  ..., -0.0114, -0.0244,  0.0630],\n",
      "        [ 0.0261, -0.0306,  0.0410,  ...,  0.0049, -0.0132, -0.0124],\n",
      "        [-0.0737,  0.0815,  0.0023,  ..., -0.0615,  0.0520,  0.0223]])), ('linear_p.weight', tensor([[ 0.0422, -0.0312,  0.0625,  ...,  0.0703, -0.0718,  0.0017],\n",
      "        [-0.0518, -0.0613, -0.0449,  ...,  0.0253, -0.0045,  0.0698],\n",
      "        [ 0.0009,  0.0007, -0.0325,  ..., -0.0182, -0.0205,  0.0012],\n",
      "        ...,\n",
      "        [-0.0742, -0.0466,  0.0645,  ..., -0.0114, -0.0244,  0.0630],\n",
      "        [ 0.0261, -0.0306,  0.0410,  ...,  0.0049, -0.0132, -0.0124],\n",
      "        [-0.0737,  0.0815,  0.0023,  ..., -0.0615,  0.0520,  0.0223]]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.head.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv_openmatch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8df0cd534818573a127d3ebdeddcb3d39a5e15b0525fc8f8321cfe8766a688f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
